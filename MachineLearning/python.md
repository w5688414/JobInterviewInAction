## p1
is用于对比对象地址,如a=7;b=7;a is b；返回为True，代表的a,b这两个变量指向的对象（7这个整形变量）为同一个。a==b返回同样为True，代表a,b这两个变量指向变量的值都为7。而a=[1,2,3];b=[1,2,3]; a is b返回为False，因为此时a,b指向的对象不是同一个了（参见Python可变数据对象），而a==b依据为True,因为这个对象的值相等。

## p2
```
装饰器最大的作用就是对于我们已经写好的程序，我们可以抽离出一些雷同的代码组建多个特定功能的装饰器，这样我们就可以针对不同的需求去使用特定的装饰器，这时因为源码去除了大量泛化的内容而使得源码具有更加清晰的逻辑。

功能：

引入日志，函数执行时间统计，执行函数前预备处理，执行函数后的清理功能，权限校验等场景，缓存
```


## *args与**args的区别
```
*args和**args适用于函数的参数不确定的时候。*args可以看做是多个变量组成的list。**args可以看做是个字典
```
## *args, **kwargs理解
```
*args 表示任何多个无名参数，它是一个tuple；**kwargs 表示关键字参数，它是一个dict。
```
python中*args, **kwargs理解. https://www.cnblogs.com/yflyaway/p/8442108.html

## 并发并行、同步异步、同步锁
```
并发：系统具有处理多个任务（动作）的能力

并行：系统具有同时处理多个任务（动作）的能力

同步：当进程执行到一个IO（等待外部数据）的时候，需要等待，等待即同步

异步：当进程执行到一个IO（等待外部数据）的时候，不需要等待，待数据接收成功后，再回来处理。

GIL:全局解释锁：无论你有多少个线程，你有多少个CPU，Python在执行的时候会淡定的在同一时刻只允许一个线程运行。（解释器层面保护进程安全）

GIL的作用：同一时刻，只有一个线程被CPU在执行，造成单线程运行结果，多核用不到。

垃圾回收机制：解释器的一个线程在进行垃圾回收。

CPU切换：io阻塞、cpu执行时间窗口等

线程都是竞争CPU资源来获得执行。

任务：io密集型（io交互多，CPU空闲时间多）、计算密集型（），time.sleep()等同于io操作

对于io密集型任务，python的多线程是有意义的，而计算密集型任务，python的多线程就不适用了，可以采用多进程。

同步锁：即将线程设置成串行，lock=threading.lock(),lock.acquire(),lock.release()
```
https://www.cnblogs.com/benchdog/p/9175574.html

## C++ 反射机制
```
C++并不支持反射机制，只能自己实现。

如果需要实现字字符串到函数到映射，一定要使用到函数指针。

简单实现反射机制，根据字符串来构造相应到类。主要有以下几点：

(1) 可以使用map保存字符从到函数指针到映射。

(2) 工厂类提供字符串与函数指针到注册关系。

(3) 工厂模式根据不同到字符串构造不同到类对象。
```
## 并发之协程
```
协程不同于线程，线程是抢占式的调度，而协程是协同式的调度，协程需要自己做调度。 
子程序调用总是一个入口，一次返回，调用顺序是明确的。而协程的调用和子程序不同。协程看上去也是子程序，但执行过程中，在子程序内部可中断，然后转而执行别的子程序，在适当的时候再返回来接着执行。

协程优势是极高的执行效率。因为子程序切换不是线程切换，而是由程序自身控制，因此，没有线程切换的开销，和多线程比，线程数量越多，协程的性能优势就越明显。用来执行协程多任务非常合适。

协程没有线程的安全问题。一个进程可以同时存在多个协程，但是只有一个协程是激活的，而且协程的激活和休眠又程序员通过编程来控制，而不是操作系统控制的。 
因为协程是一个线程中执行，那怎么利用多核CPU呢？最简单的方法是多进程+协程，既充分利用多核，又充分发挥协程的高效率，可获得极高的性能。

yield 关键字

```
python并发之协程. https://blog.csdn.net/dutsoft/article/details/54729480

## 什么是lambda函数？它有什么好处?
lambda 函数是一个可以接收任意多个参数(包括可选参数)并且返回单个表达式值的函数。 lambda 函数不能包含命令，它们所包含的表达式不能超过一个。不要试图向lambda 函数中塞入太多的东西；如果你需要更复杂的东西，应该定义一个普通函数，然后想让它多长就多长。

## 描述yield作用
1. 保存当前运行状态（断点），然后暂停执行，即将函数挂起
2. 将yeild关键字后面表达式的值作为返回值返回，此时可以理解为起到了return的作用，当使用next()、send()函数让函数从断点处继续执行，即唤醒函数。

## 简要描述Python的垃圾回收机制（garbage collection）
- Python在内存中存储了每个对象的引用计数（reference count）。如果计数值变成0，那么相应的对象就会小时，分配给该对象的内存就会释放出来用作他用。
- 偶尔也会出现引用循环（reference cycle）。垃圾回收器会定时寻找这个循环，并将其回收。举个例子，假设有两个对象o1和o2，而且符合o1.x == o2和o2.x == o1这两个条件。如果o1和o2没有其他代码引用，那么它们就不应该继续存在。但它们的引用计数都是1。
- Python中使用了某些启发式算法（heuristics）来加速垃圾回收。例如，越晚创建的对象更有可能被回收。对象被创建之后，垃圾回收器会分配它们所属的代（generation）。每个对象都会被分配一个代，而被分配更年轻代的对象是优先被处理的。

## 多线程和多进程的理解
1. 进程是系统进行资源分配和调度的一个独立单位，线程是进程的一个实体,是CPU调度和分派的基本单位,它是比进程更小的能独立运行的基本单位.线程自己基本上不拥有系统资源,只拥有一点在运行中必不可少的资源(如程序计数器,一组寄存器和栈),但是它可与同属一个进程的其他的线程共享进程所拥有的全部资源；
2. 一个程序至少有一个进程,一个进程至少有一个线程；
3. 线程的划分尺度小于进程(资源比进程少)，使得多线程程序的并发性高；
4. 进程在执行过程中拥有独立的内存单元，而多个线程共享内存，从而极大地提高了程序的运行效率 ；
5. 线程不能够独立执行，必须依存在进程中；
6. 优缺点：线程和进程在使用上各有优缺点：线程执行开销小，但不利于资源的管理和保护；而进程正相反。

## 线程中start方法和run方法的区别
1. 若调用start,则先执行主进程，后执行子进程；
2. 若调用run，相当于正常的函数调用，将按照程序的顺序执行

## Linux命令：grep,awk,sed
https://www.cnblogs.com/52fhy/p/5836429.html

## python是怎么进行内存管理
1. 引用计数：python内部使用引用计数，来保持追踪内存中的对象，Python内部记录了对象有多少个引用，即引用计数，当对象被创建时就创建了一个引用计数，当对象不再需要时，这个对象的引用计数为0时，它被垃圾回收。
- 引用计数加1的情况：
  1.1 对象被创建：x=4
  1.2 另外的别人被创建：y=x
  1.3 被作为参数传递给函数：foo(x)
  1.4 作为容器对象的一个元素：a=[1,x,'33']
- 引用计数减少情况
  1.1 一个本地引用离开了它的作用域。比如上面的foo(x)函数结束时，x指向的对象引用减1。
  1.2 对象的别名被显式的销毁：del x ；或者del y
  1.3 对象的一个别名被赋值给其他对象：x=789
  1.4 对象从一个窗口对象中移除：myList.remove(x)
  1.5 窗口对象本身被销毁：del myList，或者窗口对象本身离开了作用域
2. 垃圾回收
2.1 当内存中有不再使用的部分时，垃圾收集器就会把他们清理掉。它会去检查那些引用计数为0的对象，然后清除其在内存的空间。当然除了引用计数为0的会被清除，还有一种情况也会被垃圾收集器清掉：当两个对象相互引用时，他们本身其他的引用已经为0了。
2.2 垃圾回收机制还有一个循环垃圾回收器, 确保释放循环引用对象(a引用b, b引用a, 导致其引用计数永远不为0)。

3. 内存池机制：在Python中，许多时候申请的内存都是小块的内存，这些小块内存在申请后，很快又会被释放，由于这些内存的申请并不是为了创建对象，所以并没有对象一级的内存池机制。这就意味着Python在运行期间会大量地执行malloc和free的操作，频繁地在用户态和核心态之间进行切换，这将严重影响Python的执行效率。为了加速Python的执行效率，Python引入了一个内存池机制，用于管理对小块内存的申请和释放。

3.1 Python提供了对内存的垃圾收集机制，但是它将不用的内存放到内存池而不是返回给操作系统。
3.2 Python中所有小于256个字节的对象都使用pymalloc实现的分配器，而大的对象则使用系统的 malloc。另外Python对象，如整数，浮点数和List，都有其独立的私有内存池，对象间不共享他们的内存池。也就是说如果你分配又释放了大量的整数，用于缓存这些整数的内存就不能再分配给浮点数。

## 简述一下你熟悉的NOSQL，它有什么优点和缺点？redis
优点：

- 读写性能优异；
- 支持数据持久化，支持AOF和RDB两种持久化方式；
- 支持主从复制，主机会自动将数据同步到从机，可以进行读写分离；
- 数据结构丰富：除了支持string类型的value外还支持string、hash、set、sortedset、list等数据结构。 

缺点：   
- Redis不具备自动容错和恢复功能，主机从机的宕机都会导致前端部分读写请求失败，需要等待机器重启或者手动切换前端的IP才能恢复；
- 主机宕机，宕机前有部分数据未能及时同步到从机，切换IP后还会引入数据不一致的问题，降低了系统的可用性;
- Redis的主从复制采用全量复制，复制过程中主机会fork出一个子进程对内存做一份快照，并将子进程的内存快照保存为文件发送给从机，这一过程需要确保主机有足够多的空余内存。若快照文件较大，对集群的服务能力会产生较大的影响，而且复制过程是在从机新加入集群或者从机和主机网络断开重连时都会进行，也就是网络波动都会造成主机和从机间的一次全量的数据复制，这对实际的系统运营造成了不小的麻烦;
-  Redis较难支持在线扩容，在集群容量达到上限时在线扩容会变得很复杂。为避免这一问题，运维人员在系统上线时必须确保有足够的空间，这对资源造成了很大的浪费。

## 大数据的文件读取
① 利用生成器generator
② 迭代器进行迭代遍历：for line in file

## 迭代器和生成器的区别
1. 迭代器是一个更抽象的概念，任何对象，如果它的类有next方法和iter方法返回自己本身。对于string、list、dict、tuple等这类容器对象，使用for循环遍历是很方便的。在后台for语句对容器对象调用iter()函数，iter()是python的内置函数。iter()会返回一个定义了next()方法的迭代器对象，它在容器中逐个访问容器内元素，next()也是python的内置函数。在没有后续元素时，next()会抛出一个StopIteration异常
2. 生成器（Generator）是创建迭代器的简单而强大的工具。它们写起来就像是正规的函数，只是在需要返回数据的时候使用yield语句。每次next()被调用时，生成器会返回它脱离的位置（它记忆语句最后一次执行的位置和所有的数据值）

区别：生成器能做到迭代器能做的所有事,而且因为自动创建了__iter__()和next()方法,生成器显得特别简洁,而且生成器也是高效的，使用生成器表达式取代列表解析可以同时节省内存。除了创建和保存程序状态的自动方法,当发生器终结时,还会自动抛出StopIteration异常

## find和grep
grep命令是一种强大的文本搜索工具，grep搜索内容串可以是正则表达式，允许对文本文件进行模式查找。如果找到匹配模式，grep打印包含模式的所有行。

find通常用来再特定的目录下搜索符合条件的文件，也可以用来搜索特定用户属主的文件。

## 线上服务可能因为种种原因导致挂掉怎么办？
linux下的后台进程管理利器 supervisor
每次文件修改后再linux执行 service supervisord restart

## python的运行效率
使用生成器；关键代码使用外部功能包（Cython，pylnlne，pypy，pyrex）；针对循环的优化--尽量避免在循环中访问变量的属性



